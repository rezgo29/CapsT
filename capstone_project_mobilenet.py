# -*- coding: utf-8 -*-
"""capstone project MobileNet

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cjR8A3KGZ225BMvNm75QIG9xl54Tq_TR
"""

# !pip install kaggle

# # Create .kaggle directory and upload kaggle.jso  n
# !mkdir -p ~/.kaggle
# !cp kaggle.json ~/.kaggle/
# !chmod 600 ~/.kaggle/kaggle.json

# !kaggle datasets download -d nirmalsankalana/rice-leaf-disease-image

# !unzip /content/rice-leaf-disease-image.zip -d /kaggle/input/rice-leaf-disease-image

import os
import zipfile
import random
import shutil
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.preprocessing import image
import numpy as np
import pickle
from google.colab import files

source_path = '/kaggle/input/rice-leaf-disease-image'
source_path_Bacterialblight = os.path.join(source_path, 'Bacterialblight')
source_path_Blast = os.path.join(source_path, 'Blast')
source_path_Brownspot = os.path.join(source_path, 'Brownspot')
source_path_Tungro = os.path.join(source_path, 'Tungro')

# os.listdir returns a list containing all files under the given path
print(f"There are {len(os.listdir(source_path_Bacterialblight))} images of Bacterialblight.")
print(f"There are {len(os.listdir(source_path_Blast))} images of Blast.")
print(f"There are {len(os.listdir(source_path_Brownspot))} images of Brownspot.")
print(f"There are {len(os.listdir(source_path_Tungro))} images of Tungro.")

# Fungsi untuk menampilkan satu gambar dari setiap kelas
def show_sample_image(image_dir, class_name):
    image_path = os.path.join(image_dir, os.listdir(image_dir)[0])
    img = mpimg.imread(image_path)
    plt.imshow(img)
    plt.title(class_name)
    plt.axis('off')

# Menampilkan satu gambar dari setiap kelas
plt.figure(figsize=(5, 5))

plt.subplot(2, 2, 1)
show_sample_image(source_path_Bacterialblight, 'Bacterialblight')

plt.subplot(2, 2, 2)
show_sample_image(source_path_Blast, 'Blast')

plt.subplot(2, 2, 3)
show_sample_image(source_path_Brownspot, 'Brownspot')

plt.subplot(2, 2, 4)
show_sample_image(source_path_Tungro, 'Tungro')

plt.show()

root_dir = '/kaggle/working/RLDI'
if os.path.exists(root_dir):
    shutil.rmtree(root_dir)

def create_train_val_dirs(root_path):
    os.makedirs(os.path.join(root_path, 'training/Bacterialblight'))
    os.makedirs(os.path.join(root_path, 'training/Blast'))
    os.makedirs(os.path.join(root_path, 'training/Brownspot'))
    os.makedirs(os.path.join(root_path, 'training/Tungro'))
    os.makedirs(os.path.join(root_path, 'validation/Bacterialblight'))
    os.makedirs(os.path.join(root_path, 'validation/Blast'))
    os.makedirs(os.path.join(root_path, 'validation/Brownspot'))
    os.makedirs(os.path.join(root_path, 'validation/Tungro'))
    os.makedirs(os.path.join(root_path, 'test'))


try:
    create_train_val_dirs(root_path=root_dir)
except FileExistsError:
    print("You should not be seeing this since the upper directory is removed beforehand")

for rootdir, dirs, files in os.walk(root_dir):
    for subdir in dirs:
        print(os.path.join(rootdir, subdir))

def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, TEST_DIR, SPLIT_SIZE):
    source_files = os.listdir(SOURCE_DIR)
    random.shuffle(source_files)

    num_images = len(source_files)
    num_training = int(num_images * SPLIT_SIZE[0])
    num_validation = int(num_images * SPLIT_SIZE[1])

    training_images = source_files[:num_training]
    validation_images = source_files[num_training:num_training+num_validation]
    test_images = source_files[num_training+num_validation:]

    for image_name in training_images:
        shutil.copyfile(os.path.join(SOURCE_DIR, image_name),
                        os.path.join(TRAINING_DIR, image_name))

    for image_name in validation_images:
        shutil.copyfile(os.path.join(SOURCE_DIR, image_name),
                        os.path.join(VALIDATION_DIR, image_name))

    for image_name in test_images:
        shutil.copyfile(os.path.join(SOURCE_DIR, image_name),
                        os.path.join(TEST_DIR, image_name))

Bacterialblight_SOURCE_DIR = "/kaggle/input/rice-leaf-disease-image/Bacterialblight"
Blast_SOURCE_DIR = "/kaggle/input/rice-leaf-disease-image/Blast"
Brownspot_SOURCE_DIR = "/kaggle/input/rice-leaf-disease-image/Brownspot"
Tungro_SOURCE_DIR = "/kaggle/input/rice-leaf-disease-image/Tungro"

TRAINING_DIR = "/kaggle/working/RLDI/training"
VALIDATION_DIR = "/kaggle/working/RLDI/validation"
TEST_DIR = "/kaggle/working/RLDI/test"


TRAINING_Bacterialblight_DIR = os.path.join(TRAINING_DIR, "Bacterialblight/")
VALIDATION_Bacterialblight_DIR = os.path.join(VALIDATION_DIR, "Bacterialblight/")

TRAINING_Blast_DIR = os.path.join(TRAINING_DIR, "Blast/")
VALIDATION_Blast_DIR = os.path.join(VALIDATION_DIR, "Blast/")

TRAINING_Brownspot_DIR = os.path.join(TRAINING_DIR, "Brownspot/")
VALIDATION_Brownspot_DIR = os.path.join(VALIDATION_DIR, "Brownspot/")


TRAINING_Tungro_DIR = os.path.join(TRAINING_DIR, "Tungro/")
VALIDATION_Tungro_DIR = os.path.join(VALIDATION_DIR, "Tungro/")

# Empty directories in case you run this cell multiple times
if len(os.listdir(TRAINING_Bacterialblight_DIR)) > 0:
  for file in os.scandir(TRAINING_Bacterialblight_DIR):
    os.remove(file.path)
if len(os.listdir(TRAINING_Blast_DIR)) > 0:
  for file in os.scandir(TRAINING_Blast_DIR):
    os.remove(file.path)
if len(os.listdir(TRAINING_Brownspot_DIR)) > 0:
  for file in os.scandir(TRAINING_Brownspot_DIR):
    os.remove(file.path)
if len(os.listdir(TRAINING_Tungro_DIR)) > 0:
  for file in os.scandir(TRAINING_Tungro_DIR):
    os.remove(file.path)

if len(os.listdir(VALIDATION_Bacterialblight_DIR)) > 0:
  for file in os.scandir(VALIDATION_Bacterialblight_DIR):
    os.remove(file.path)
if len(os.listdir(VALIDATION_Blast_DIR)) > 0:
  for file in os.scandir(VALIDATION_Blast_DIR):
    os.remove(file.path)
if len(os.listdir(VALIDATION_Blast_DIR)) > 0:
  for file in os.scandir(VALIDATION_Blast_DIR):
    os.remove(file.path)
if len(os.listdir(VALIDATION_Tungro_DIR)) > 0:
  for file in os.scandir(VALIDATION_Tungro_DIR):
    os.remove(file.path)


# Split data untuk setiap kelas
split_data(Bacterialblight_SOURCE_DIR, TRAINING_Bacterialblight_DIR, VALIDATION_Bacterialblight_DIR, TEST_DIR, [0.7, 0.15])
split_data(Blast_SOURCE_DIR , TRAINING_Blast_DIR, VALIDATION_Blast_DIR, TEST_DIR, [0.85, 0.1])
split_data(Brownspot_SOURCE_DIR,TRAINING_Brownspot_DIR, VALIDATION_Brownspot_DIR, TEST_DIR, [0.85, 0.1])
split_data(Tungro_SOURCE_DIR, TRAINING_Tungro_DIR,VALIDATION_Tungro_DIR, TEST_DIR, [0.85, 0.1])

print(f"\n\nOriginal Bacterialblight's directory has {len(os.listdir(Bacterialblight_SOURCE_DIR))} images")
print(f"Original Blast's directory has {len(os.listdir(Blast_SOURCE_DIR))} images")
print(f"Original Brownspot's directory has {len(os.listdir(Brownspot_SOURCE_DIR))} images")
print(f"Original Tungro's directory has {len(os.listdir(Tungro_SOURCE_DIR))} images")

# Menampilkan jumlah data di setiap direktori
print(f"\nThere are {len(os.listdir(TRAINING_Bacterialblight_DIR))} images of Bacterialblight for training")
print(f"There are {len(os.listdir(TRAINING_Blast_DIR))} images of Blast for training")
print(f"There are {len(os.listdir(TRAINING_Brownspot_DIR))} images of Brownspot for training")
print(f"There are {len(os.listdir(TRAINING_Tungro_DIR))} images of Tungro for training")

print(f"\nThere are {len(os.listdir(VALIDATION_Bacterialblight_DIR))} images of Bacterialblight for validation")
print(f"There are {len(os.listdir(VALIDATION_Blast_DIR))} images of Blast for validation")
print(f"There are {len(os.listdir(VALIDATION_Brownspot_DIR))} images of Brownspot for validation")
print(f"There are {len(os.listdir(VALIDATION_Tungro_DIR))} images of Tungro for validation")

print(f"\nThere are {len(os.listdir(TEST_DIR))} images in the test directory")

def train_val_generators(TRAINING_DIR, VALIDATION_DIR):

  train_datagen = ImageDataGenerator(rescale=1/255)

  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,
                                                      batch_size=32,
                                                      class_mode='categorical',
                                                      target_size=(224, 224))

  validation_datagen = ImageDataGenerator(rescale=1/255)

  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,
                                                                batch_size=32,
                                                                class_mode='categorical',
                                                                target_size=(224, 224))

  return train_generator, validation_generator

train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)

# Load pre-trained MobileNetV2 model and exclude the top layers
base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')

# Freeze the base model
base_model.trainable = False

# Add custom layers on top of the base model
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(4, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(train_generator,
                    epochs=15,
                    verbose=1,
                    validation_data=validation_generator)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training Accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.show()

plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

import tensorflow as tf
from tensorflow import keras
import pickle
from google.colab import files

# Asumsikan `history` adalah variabel yang menyimpan hasil pelatihan model
# Simpan history pelatihan
with open('history.pkl', 'wb') as f:
    pickle.dump(history.history, f)

# Unduh file history
files.download('history.pkl')

# Simpan model
model.save('my_model.h5')

# Unduh model
files.download('my_model.h5')

# Konversi ke TensorFlow Lite dari file HDF5
converter = tf.lite.TFLiteConverter.from_keras_model_file('my_model.h5')
tflite_model = converter.convert()

# Simpan model .tflite
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

# Unduh model .tflite
files.download('model.tflite')

# Memuat model yang telah dilatih
model = tf.keras.models.load_model('/content/my_model.h5')

def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0
    return img_array

def predict_image(model, img_path):
    img_array = preprocess_image(img_path)
    prediction = model.predict(img_array)
    return prediction

# Path gambar yang diunggah
uploaded_image_path = '/kaggle/working/RLDI/test/BACTERAILBLIGHT3_002.jpg'  # Ganti dengan path gambar yang diunggah

# Menampilkan gambar
img = image.load_img(uploaded_image_path)
plt.imshow(img)
plt.axis('off')
plt.show()

# Melakukan prediksi
prediction = predict_image(model, uploaded_image_path)

# klasifikasi kategorikal dengan 4 kelas
class_names = ['Bacterialblight', 'Blast', 'Brownspot', 'Tungro']
predicted_class = np.argmax(prediction[0])
print(f"Prediksi: {class_names[predicted_class]}")

# import tensorflow as tf
# from tensorflow.keras.preprocessing import image
# import numpy as np
# from google.colab import files
# import matplotlib.pyplot as plt

# # Memuat model yang telah dilatih
# model = tf.keras.models.load_model('/content/my_model.h5')

# def preprocess_image(img_path):
#     img = image.load_img(img_path, target_size=(224, 224))
#     img_array = image.img_to_array(img)
#     img_array = np.expand_dims(img_array, axis=0)
#     img_array /= 255.0
#     return img_array

# def predict_image(model, img_path):
#     img_array = preprocess_image(img_path)
#     prediction = model.predict(img_array)
#     return prediction

# # Mengunggah gambar
# uploaded = files.upload()

# for file_name in uploaded.keys():
#     img_path = file_name

#     # Menampilkan gambar yang diunggah
#     img = image.load_img(img_path)
#     plt.imshow(img)
#     plt.axis('off')
#     plt.show()

#     # Melakukan prediksi
#     prediction = predict_image(model, img_path)

#     # Misalkan model Anda adalah categorical classifier dengan 4 kelas
#     class_names = ['Bacterialblight', 'Blast', 'Brownspot', 'Tungro']
#     predicted_class = np.argmax(prediction[0])
#     print(f"Prediksi: {class_names[predicted_class]}")

